from google.colab import drive                     // connecting through google collab , as all data are stored in g drive only
drive.mount('/content/gdrive')

import os                                          // importing necessary libraries
import numpy as np
import cv2
from keras.preprocessing.image import ImageDataGenerator

base_dir = '/content/gdrive/My Drive/new_data'     // location of data stored in google drive   
direction_path = [ os.path.join(base_dir,p)  for p in os.listdir(base_dir)]

direction_path

X = []
Y = []
for i,path in enumerate(direction_path):
  j = 0
  for img in os.listdir(path):
    
    if j == 900:
      break
    try:
      img_path = os.path.join(path,img)
      IMG = cv2.imread(img_path)
      IMG = cv2.resize(IMG, (128,128))
      IMG = np.array(IMG).astype('float32') / 255.
      X.append(IMG)
      Y.append(i)
      j+=1
    except Exception as e:
      print(str(e)) 
      
X1 = np.array(X)
Y1 = np.array(Y)

from keras.utils import to_categorical

Y1 = to_categorical(Y1 , num_classes = 5)                       // no. of classes used here it is 5 for frwrd,left,right,sharp left,sharp right

print(X1.shape)
print(Y1.shape)

from sklearn.model_selection import train_test_split
X_train, X_test , y_train, y_test = train_test_split(X1, Y1, test_size = 0.2)
print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

model.compile(loss = 'binary_crossentropy' , optimizer = 'adam', metrics = ['accuracy'])

model.fit(X_train, y_train, epochs = 18, validation_split = 0.2, batch_size = 15)

model.evaluate(X_test,y_test)

model.predict_classes(X_test)

model.save("output.h4")        // the file is saved as output.h4
